{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45591d15",
   "metadata": {},
   "source": [
    "# Multi-Domain Specialized Agent System\n",
    "\n",
    "This notebook implements a multi-agent system with specialized domains (Mechanical, Electrical, Programming) \n",
    "and multiple output agents for generating different types of content:\n",
    "\n",
    "1. **Domain Experts**:\n",
    "   - Mechanical Engineering Expert\n",
    "   - Electrical Engineering Expert  \n",
    "   - Programming/Software Expert\n",
    "\n",
    "2. **Output Agents**:\n",
    "   - Architecture Diagram Generator\n",
    "   - PowerPoint Generator\n",
    "   - Word Document Generator\n",
    "   - PDF Creator\n",
    "   - Code Generator\n",
    "\n",
    "The system uses Ollama with Llama 3.2 for reasoning and prompt generation, and external agent functions for specific tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7303741d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… aiohttp available for API interactions\n",
      "âœ… Langchain available for agent coordination\n",
      "âœ… Basic imports loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Basic imports\n",
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import asyncio\n",
    "from typing import Dict, List, Any, Optional, Union\n",
    "from dataclasses import dataclass, asdict\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "\n",
    "# Langchain imports\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.llms import Ollama\n",
    "\n",
    "# HTTP client for API interactions\n",
    "try:\n",
    "    import aiohttp\n",
    "    AIOHTTP_AVAILABLE = True\n",
    "    print(\"âœ… aiohttp available for API interactions\")\n",
    "except ImportError:\n",
    "    AIOHTTP_AVAILABLE = False\n",
    "    print(\"âš ï¸ aiohttp not installed. Install with: pip install aiohttp\")\n",
    "\n",
    "# Langchain setup\n",
    "try:\n",
    "    from langchain.llms import Ollama\n",
    "    LANGCHAIN_AVAILABLE = True\n",
    "    print(\"âœ… Langchain available for agent coordination\")\n",
    "except ImportError:\n",
    "    LANGCHAIN_AVAILABLE = False\n",
    "    print(\"âš ï¸ Langchain not installed. Install with: pip install langchain\")\n",
    "\n",
    "print(\"âœ… Basic imports loaded successfully!\")\n",
    "\n",
    "# Create storage directory for outputs if it doesn't exist\n",
    "DATA_DIR = Path(\"./data\")\n",
    "DATA_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a708c84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Core data structures defined with workflow support!\n"
     ]
    }
   ],
   "source": [
    "# Core data structures\n",
    "@dataclass\n",
    "class DomainExpertInput:\n",
    "    \"\"\"Input for a domain expert\"\"\"\n",
    "    user_query: str\n",
    "    context: Optional[str] = None\n",
    "    domain_name: str = \"\"\n",
    "    additional_instructions: Optional[str] = None\n",
    "    \n",
    "@dataclass\n",
    "class DomainExpertOutput:\n",
    "    \"\"\"Output from a domain expert\"\"\"\n",
    "    domain: str\n",
    "    analysis: str  \n",
    "    concerns: List[str]\n",
    "    recommendations: List[str]\n",
    "    compatibility_notes: Optional[List[str]] = None\n",
    "    timestamp: str = datetime.now().isoformat()\n",
    "    \n",
    "@dataclass \n",
    "class GeneratedPrompt:\n",
    "    \"\"\"Container for generated prompts\"\"\"\n",
    "    prompt_type: str  # 'domain' or 'agent'\n",
    "    agent_name: str\n",
    "    prompt_content: str\n",
    "    timestamp: str = datetime.now().isoformat()\n",
    "    file_path: Optional[str] = None\n",
    "    \n",
    "@dataclass\n",
    "class WorkflowStep:\n",
    "    \"\"\"Represents a step in the agent workflow\"\"\"\n",
    "    step_id: str\n",
    "    agent_type: str\n",
    "    dependencies: List[str]  # List of step_ids this step depends on\n",
    "    accumulated_prompt: str = \"\"  # Combined prompt from all previous steps\n",
    "    generated_prompt: Optional[GeneratedPrompt] = None\n",
    "    executed: bool = False\n",
    "    output: Optional[Any] = None\n",
    "\n",
    "@dataclass\n",
    "class AgentExecutionRequest:\n",
    "    \"\"\"Request to execute a specific agent\"\"\"\n",
    "    agent_type: str\n",
    "    user_query: str\n",
    "    domain_outputs: Dict[str, DomainExpertOutput]\n",
    "    workflow_context: Dict[str, WorkflowStep] = None  # Added workflow context\n",
    "    specific_instructions: Optional[str] = None\n",
    "    \n",
    "@dataclass\n",
    "class AgentOutput:\n",
    "    \"\"\"Output from a specific agent\"\"\"\n",
    "    agent_type: str\n",
    "    content: Any\n",
    "    format: str\n",
    "    file_path: Optional[str] = None\n",
    "    execution_time: float = 0.0\n",
    "    timestamp: str = datetime.now().isoformat()\n",
    "    \n",
    "@dataclass\n",
    "class SystemState:\n",
    "    \"\"\"Overall system state\"\"\"\n",
    "    conversation_id: str\n",
    "    user_query: str\n",
    "    domain_outputs: Dict[str, DomainExpertOutput]\n",
    "    agent_outputs: Dict[str, AgentOutput] \n",
    "    conversation_history: List[Dict[str, str]]\n",
    "    generated_prompts: Dict[str, GeneratedPrompt] = None  # Store all prompts\n",
    "    workflow_steps: Dict[str, WorkflowStep] = None  # Store workflow steps\n",
    "    last_updated: str = datetime.now().isoformat()\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"Initialize default values\"\"\"\n",
    "        if self.generated_prompts is None:\n",
    "            self.generated_prompts = {}\n",
    "        if self.workflow_steps is None:\n",
    "            self.workflow_steps = {}\n",
    "    \n",
    "    def save_to_json(self, file_path: Optional[str] = None) -> str:\n",
    "        \"\"\"Save system state to JSON file\"\"\"\n",
    "        if file_path is None:\n",
    "            file_path = f\"./data/system_state_{self.conversation_id[:8]}.json\"\n",
    "        \n",
    "        # Convert to dictionary with proper serialization\n",
    "        state_dict = {\n",
    "            \"conversation_id\": self.conversation_id,\n",
    "            \"user_query\": self.user_query,\n",
    "            \"domain_outputs\": {k: asdict(v) for k, v in self.domain_outputs.items()},\n",
    "            \"agent_outputs\": {k: asdict(v) for k, v in self.agent_outputs.items()},\n",
    "            \"conversation_history\": self.conversation_history,\n",
    "            \"generated_prompts\": {k: asdict(v) for k, v in self.generated_prompts.items()},\n",
    "            \"workflow_steps\": {k: asdict(v) for k, v in self.workflow_steps.items()},\n",
    "            \"last_updated\": self.last_updated\n",
    "        }\n",
    "        \n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(state_dict, f, indent=2)\n",
    "        \n",
    "        return file_path\n",
    "    \n",
    "    @classmethod\n",
    "    def load_from_json(cls, file_path: str) -> 'SystemState':\n",
    "        \"\"\"Load system state from JSON file\"\"\"\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Convert dictionaries back to dataclasses\n",
    "        domain_outputs = {k: DomainExpertOutput(**v) for k, v in data['domain_outputs'].items()}\n",
    "        agent_outputs = {k: AgentOutput(**v) for k, v in data['agent_outputs'].items()}\n",
    "        generated_prompts = {k: GeneratedPrompt(**v) for k, v in data.get('generated_prompts', {}).items()}\n",
    "        workflow_steps = {k: WorkflowStep(**v) for k, v in data.get('workflow_steps', {}).items()}\n",
    "        \n",
    "        return cls(\n",
    "            conversation_id=data['conversation_id'],\n",
    "            user_query=data['user_query'],\n",
    "            domain_outputs=domain_outputs,\n",
    "            agent_outputs=agent_outputs,\n",
    "            conversation_history=data['conversation_history'],\n",
    "            generated_prompts=generated_prompts,\n",
    "            workflow_steps=workflow_steps,\n",
    "            last_updated=data['last_updated']\n",
    "        )\n",
    "\n",
    "# Define domain expert types\n",
    "class DomainType(Enum):\n",
    "    MECHANICAL = \"mechanical\"\n",
    "    ELECTRICAL = \"electrical\"\n",
    "    PROGRAMMING = \"programming\"\n",
    "    \n",
    "# Define agent types\n",
    "class AgentType(Enum):\n",
    "    DIAGRAM = \"diagram\"\n",
    "    PRESENTATION = \"presentation\"\n",
    "    DOCUMENT = \"document\"\n",
    "    PDF = \"pdf\"\n",
    "    CODE = \"code\"\n",
    "\n",
    "print(\"âœ… Core data structures defined with workflow support!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "317ab70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LLM configuration created!\n"
     ]
    }
   ],
   "source": [
    "# LLM Configuration\n",
    "class LLMConfig:\n",
    "    \"\"\"Configuration for LLM interactions\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        base_url: str = \"http://127.0.0.1:11434\",\n",
    "        model_name: str = \"llama3.2\",  # or llama3:8b, llama3:70b based on your local setup\n",
    "        temperature: float = 0.7,\n",
    "        timeout: int = 60\n",
    "    ):\n",
    "        self.base_url = base_url\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "        self.timeout = timeout\n",
    "        \n",
    "        \n",
    "    def get_langchain_llm(self):\n",
    "        \"\"\"Get LLM instance for Langchain\"\"\"\n",
    "        if not LANGCHAIN_AVAILABLE:\n",
    "            print(\"âš ï¸ Langchain not available, using mock responses\")\n",
    "            exit(0)\n",
    "        \n",
    "            \n",
    "        try:\n",
    "            return Ollama(\n",
    "                model=self.model_name,\n",
    "                base_url=self.base_url,\n",
    "                temperature=self.temperature,\n",
    "                timeout=self.timeout\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error creating Ollama LLM: {e}\")\n",
    "            print(\"ðŸŽ­ Falling back to mock responses\")\n",
    "            exit(0)\n",
    "            \n",
    "        \n",
    "\n",
    "# Test LLM configuration  \n",
    "llm_config = LLMConfig()  # Set to False when Ollama is available\n",
    "print(\"âœ… LLM configuration created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "693658e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Workflow manager implemented!\n"
     ]
    }
   ],
   "source": [
    "# Workflow Manager for Sequential Agent Execution\n",
    "class WorkflowManager:\n",
    "    \"\"\"Manages sequential workflow execution with prompt chaining\"\"\"\n",
    "    \n",
    "    def __init__(self, conversation_id: str):\n",
    "        self.conversation_id = conversation_id\n",
    "        self.workflow_steps = {}\n",
    "        self.execution_order = []\n",
    "        \n",
    "    def create_workflow(self, agent_types: List[str]) -> Dict[str, WorkflowStep]:\n",
    "        \"\"\"Create a sequential workflow for the given agent types\"\"\"\n",
    "        self.workflow_steps = {}\n",
    "        self.execution_order = agent_types.copy()\n",
    "        \n",
    "        for i, agent_type in enumerate(agent_types):\n",
    "            step_id = f\"step_{i+1}_{agent_type}\"\n",
    "            dependencies = [f\"step_{i}_{agent_types[i-1]}\"] if i > 0 else []\n",
    "            \n",
    "            self.workflow_steps[step_id] = WorkflowStep(\n",
    "                step_id=step_id,\n",
    "                agent_type=agent_type,\n",
    "                dependencies=dependencies\n",
    "            )\n",
    "        \n",
    "        return self.workflow_steps\n",
    "    \n",
    "    def get_accumulated_prompt(self, step_id: str, domain_prompts: Dict[str, str]) -> str:\n",
    "        \"\"\"Get accumulated prompt for a specific step\"\"\"\n",
    "        step = self.workflow_steps[step_id]\n",
    "        accumulated_prompt = \"\"\n",
    "        \n",
    "        # Add domain expert prompts first\n",
    "        domain_section = \"DOMAIN EXPERT ANALYSES:\\n\\n\"\n",
    "        for domain, prompt in domain_prompts.items():\n",
    "            domain_section += f\"=== {domain.upper()} DOMAIN ANALYSIS ===\\n{prompt}\\n\\n\"\n",
    "        \n",
    "        accumulated_prompt += domain_section\n",
    "        \n",
    "        # Add previous agent prompts\n",
    "        current_step_index = self.execution_order.index(step.agent_type)\n",
    "        if current_step_index > 0:\n",
    "            agent_section = \"PREVIOUS AGENT PROMPTS:\\n\\n\"\n",
    "            for i in range(current_step_index):\n",
    "                prev_agent_type = self.execution_order[i]\n",
    "                prev_step_id = f\"step_{i+1}_{prev_agent_type}\"\n",
    "                prev_step = self.workflow_steps[prev_step_id]\n",
    "                \n",
    "                if prev_step.generated_prompt:\n",
    "                    agent_section += f\"=== {prev_agent_type.upper()} AGENT PROMPT ===\\n\"\n",
    "                    agent_section += f\"{prev_step.generated_prompt.prompt_content}\\n\\n\"\n",
    "            \n",
    "            accumulated_prompt += agent_section\n",
    "        \n",
    "        return accumulated_prompt\n",
    "    \n",
    "    def update_step_prompt(self, step_id: str, generated_prompt: GeneratedPrompt):\n",
    "        \"\"\"Update a workflow step with generated prompt\"\"\"\n",
    "        if step_id in self.workflow_steps:\n",
    "            self.workflow_steps[step_id].generated_prompt = generated_prompt\n",
    "            self.workflow_steps[step_id].accumulated_prompt = generated_prompt.prompt_content\n",
    "    \n",
    "    def mark_step_executed(self, step_id: str, output: Any):\n",
    "        \"\"\"Mark a step as executed with output\"\"\"\n",
    "        if step_id in self.workflow_steps:\n",
    "            self.workflow_steps[step_id].executed = True\n",
    "            self.workflow_steps[step_id].output = output\n",
    "    \n",
    "    def get_steps_to_redo(self, changed_step_id: str) -> List[str]:\n",
    "        \"\"\"Get list of steps that need to be redone after a change\"\"\"\n",
    "        changed_step_index = None\n",
    "        for i, agent_type in enumerate(self.execution_order):\n",
    "            step_id = f\"step_{i+1}_{agent_type}\"\n",
    "            if step_id == changed_step_id:\n",
    "                changed_step_index = i\n",
    "                break\n",
    "        \n",
    "        if changed_step_index is None:\n",
    "            return []\n",
    "        \n",
    "        # Return all steps from the changed step onwards\n",
    "        steps_to_redo = []\n",
    "        for i in range(changed_step_index, len(self.execution_order)):\n",
    "            agent_type = self.execution_order[i]\n",
    "            step_id = f\"step_{i+1}_{agent_type}\"\n",
    "            steps_to_redo.append(step_id)\n",
    "        \n",
    "        return steps_to_redo\n",
    "    \n",
    "    def reset_steps(self, step_ids: List[str]):\n",
    "        \"\"\"Reset specified steps to unexecuted state\"\"\"\n",
    "        for step_id in step_ids:\n",
    "            if step_id in self.workflow_steps:\n",
    "                self.workflow_steps[step_id].executed = False\n",
    "                self.workflow_steps[step_id].output = None\n",
    "    \n",
    "    def save_prompts_to_files(self, base_path: str = \"./data\"):\n",
    "        \"\"\"Save all generated prompts to individual files\"\"\"\n",
    "        saved_files = {}\n",
    "        \n",
    "        for step_id, step in self.workflow_steps.items():\n",
    "            if step.generated_prompt:\n",
    "                filename = f\"{step.agent_type}_prompt_{self.conversation_id[:8]}.txt\"\n",
    "                file_path = os.path.join(base_path, filename)\n",
    "                \n",
    "                with open(file_path, 'w', encoding='utf-8') as f:\n",
    "                    f.write(f\"# {step.agent_type.upper()} AGENT PROMPT\\n\")\n",
    "                    f.write(f\"# Generated: {step.generated_prompt.timestamp}\\n\")\n",
    "                    f.write(f\"# Step ID: {step_id}\\n\\n\")\n",
    "                    f.write(step.generated_prompt.prompt_content)\n",
    "                \n",
    "                step.generated_prompt.file_path = file_path\n",
    "                saved_files[step.agent_type] = file_path\n",
    "        \n",
    "        return saved_files\n",
    "\n",
    "print(\"âœ… Workflow manager implemented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e152bf31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Domain experts implementation with prompt saving ready!\n"
     ]
    }
   ],
   "source": [
    "# Domain Experts Implementation with Prompt Saving\n",
    "class DomainExpert:\n",
    "    \"\"\"Base class for domain experts\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        domain_type: DomainType,\n",
    "        llm_config: LLMConfig\n",
    "    ):\n",
    "        self.domain_type = domain_type\n",
    "        self.llm = llm_config.get_langchain_llm()\n",
    "        self.system_prompt = self._get_domain_system_prompt()\n",
    "        \n",
    "    def _get_domain_system_prompt(self) -> str:\n",
    "        \"\"\"Get domain-specific system prompt\"\"\"\n",
    "        if self.domain_type == DomainType.MECHANICAL:\n",
    "            return \"\"\"You are an expert Mechanical Engineer with extensive experience in designing physical systems, \n",
    "mechanisms, structures, and manufacturing processes. Think exclusively from a mechanical engineering perspective.\n",
    "\n",
    "When analyzing problems:\n",
    "1. Focus on physical principles, materials, structural integrity, and mechanical systems.\n",
    "2. Consider forces, stresses, thermal effects, vibration, and material properties.\n",
    "3. Evaluate manufacturability, assembly, maintenance, and mechanical reliability.\n",
    "4. Identify potential mechanical failure points and physical constraints.\n",
    "5. Always prioritize safety, durability, and mechanical efficiency.\n",
    "\n",
    "Provide specific mechanical engineering insights with technical depth. Don't discuss electrical or software aspects \n",
    "unless they directly impact the mechanical design. Use precise mechanical engineering terminology.\n",
    "\n",
    "Your analysis should include:\n",
    "- Core mechanical principles that apply\n",
    "- Material recommendations\n",
    "- Structural considerations\n",
    "- Thermal and vibration management\n",
    "- Manufacturing approach\n",
    "- Mechanical limitations and concerns\"\"\"\n",
    "\n",
    "        elif self.domain_type == DomainType.ELECTRICAL:\n",
    "            return \"\"\"You are an expert Electrical Engineer with extensive experience in designing circuits, power systems, \n",
    "and electronic components. Think exclusively from an electrical engineering perspective.\n",
    "\n",
    "When analyzing problems:\n",
    "1. Focus on electrical principles, circuit design, power distribution, and signal integrity.\n",
    "2. Consider voltage levels, current requirements, power management, and EMI/EMC concerns.\n",
    "3. Evaluate electrical components, PCB design, wiring, and electrical safety.\n",
    "4. Identify potential electrical failure modes and constraints.\n",
    "5. Always prioritize electrical safety, reliability, and efficiency.\n",
    "\n",
    "Provide specific electrical engineering insights with technical depth. Don't discuss mechanical or software aspects \n",
    "unless they directly impact the electrical design. Use precise electrical engineering terminology.\n",
    "\n",
    "Your analysis should include:\n",
    "- Power requirements and distribution\n",
    "- Circuit design considerations\n",
    "- Component selection guidelines\n",
    "- Signal integrity and noise concerns\n",
    "- Electrical safety measures\n",
    "- Testing and validation approaches\"\"\"\n",
    "\n",
    "        elif self.domain_type == DomainType.PROGRAMMING:\n",
    "            return \"\"\"You are an expert Software Engineer with extensive experience in designing software architectures, \n",
    "algorithms, and embedded systems. Think exclusively from a software engineering perspective.\n",
    "\n",
    "When analyzing problems:\n",
    "1. Focus on software architecture, data structures, algorithms, and system design.\n",
    "2. Consider execution efficiency, memory usage, maintainability, and scalability.\n",
    "3. Evaluate appropriate programming languages, frameworks, and development methodologies.\n",
    "4. Identify potential software failure modes and technical debt.\n",
    "5. Always prioritize code quality, maintainability, and performance.\n",
    "\n",
    "Provide specific software engineering insights with technical depth. Don't discuss mechanical or electrical aspects \n",
    "unless they directly impact the software design. Use precise software engineering terminology.\n",
    "\n",
    "Your analysis should include:\n",
    "- Software architecture recommendations\n",
    "- Data structure and algorithm considerations\n",
    "- Language and framework selection\n",
    "- Testing strategies\n",
    "- Error handling approaches\n",
    "- Performance optimization opportunities\"\"\"\n",
    "        \n",
    "        else:\n",
    "            return \"You are an engineering expert. Analyze the problem and provide technical insights.\"\n",
    "\n",
    "    async def analyze(self, input_data: DomainExpertInput, conversation_id: str) -> tuple[DomainExpertOutput, GeneratedPrompt]:\n",
    "        \"\"\"Analyze the input from domain perspective and return both output and generated prompt\"\"\"\n",
    "        \n",
    "        # Create the prompt for this domain analysis\n",
    "        context_section = f\"ADDITIONAL CONTEXT:\\n{input_data.context}\" if input_data.context else \"\"\n",
    "        instructions_section = f\"SPECIFIC INSTRUCTIONS:\\n{input_data.additional_instructions}\" if input_data.additional_instructions else \"\"\n",
    "        \n",
    "        analysis_prompt = f\"\"\"\n",
    "Analyze this requirement from your {self.domain_type.value} engineering perspective:\n",
    "\n",
    "USER REQUIREMENT:\n",
    "{input_data.user_query}\n",
    "\n",
    "{context_section}\n",
    "\n",
    "{instructions_section}\n",
    "\n",
    "Provide your analysis in this format:\n",
    "1. Core principles and considerations from your domain\n",
    "2. Key concerns and potential issues\n",
    "3. Specific recommendations and approaches\n",
    "\n",
    "Be thorough, technical, and focus exclusively on {self.domain_type.value} engineering aspects.\n",
    "\"\"\"\n",
    "\n",
    "        # Save the generated prompt\n",
    "        generated_prompt = GeneratedPrompt(\n",
    "            prompt_type=\"domain\",\n",
    "            agent_name=f\"{self.domain_type.value}_expert\",\n",
    "            prompt_content=analysis_prompt,\n",
    "            timestamp=datetime.now().isoformat()\n",
    "        )\n",
    "        \n",
    "        # Save prompt to file\n",
    "        prompt_filename = f\"{self.domain_type.value}_domain_prompt_{conversation_id[:8]}.txt\"\n",
    "        prompt_file_path = f\"./data/{prompt_filename}\"\n",
    "        with open(prompt_file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"# {self.domain_type.value.upper()} DOMAIN EXPERT PROMPT\\n\")\n",
    "            f.write(f\"# Generated: {generated_prompt.timestamp}\\n\\n\")\n",
    "            f.write(analysis_prompt)\n",
    "        \n",
    "        generated_prompt.file_path = prompt_file_path\n",
    "        \n",
    "        # Create the actual LLM prompt template\n",
    "        prompt_template = ChatPromptTemplate.from_messages([\n",
    "            SystemMessage(content=self.system_prompt),\n",
    "            HumanMessage(content=analysis_prompt)\n",
    "        ])\n",
    "        \n",
    "        chain = LLMChain(llm=self.llm, prompt=prompt_template)\n",
    "        \n",
    "        # Time the execution\n",
    "        start_time = datetime.now()\n",
    "        result = await chain.ainvoke({\"input\": input_data})\n",
    "        execution_time = (datetime.now() - start_time).total_seconds()\n",
    "        \n",
    "        # Process the output\n",
    "        analysis = result['text'] if isinstance(result, dict) and 'text' in result else str(result)\n",
    "        \n",
    "        # Extract key points\n",
    "        concerns = self._extract_concerns(analysis)\n",
    "        recommendations = self._extract_recommendations(analysis)\n",
    "        \n",
    "        domain_output = DomainExpertOutput(\n",
    "            domain=self.domain_type.value,\n",
    "            analysis=analysis,\n",
    "            concerns=concerns,\n",
    "            recommendations=recommendations\n",
    "        )\n",
    "        \n",
    "        return domain_output, generated_prompt\n",
    "    \n",
    "    def _extract_concerns(self, analysis: str) -> List[str]:\n",
    "        \"\"\"Extract key concerns from analysis\"\"\"\n",
    "        # Simple extraction based on key phrases and formatting\n",
    "        concerns = []\n",
    "        lines = analysis.split('\\n')\n",
    "        in_concerns_section = False\n",
    "        \n",
    "        for line in lines:\n",
    "            if \"concerns\" in line.lower() or \"issues\" in line.lower():\n",
    "                in_concerns_section = True\n",
    "                continue\n",
    "                \n",
    "            if in_concerns_section and (line.strip() == \"\" or \"recommendations\" in line.lower()):\n",
    "                in_concerns_section = False\n",
    "                continue\n",
    "                \n",
    "            if in_concerns_section and line.strip():\n",
    "                # Clean up bullet points and numbering\n",
    "                clean_line = line.strip()\n",
    "                for prefix in ['-', 'â€¢', '*', 'â—‹', 'âž¢', 'â†’']:\n",
    "                    if clean_line.startswith(prefix):\n",
    "                        clean_line = clean_line[1:].strip()\n",
    "                        \n",
    "                # Remove numbering like \"1.\" or \"1)\"\n",
    "                if clean_line and clean_line[0].isdigit() and clean_line[1:3] in ['. ', ') ']:\n",
    "                    clean_line = clean_line[3:].strip()\n",
    "                    \n",
    "                if clean_line:\n",
    "                    concerns.append(clean_line)\n",
    "        \n",
    "        # If we couldn't extract structured concerns, do a simpler extraction\n",
    "        if not concerns:\n",
    "            concerns = [line.strip() for line in analysis.split('\\n') \n",
    "                     if \"concern\" in line.lower() or \"issue\" in line.lower()]\n",
    "        \n",
    "        return concerns[:5]  # Limit to top 5 concerns\n",
    "    \n",
    "    def _extract_recommendations(self, analysis: str) -> List[str]:\n",
    "        \"\"\"Extract recommendations from analysis\"\"\"\n",
    "        # Similar to concerns extraction\n",
    "        recommendations = []\n",
    "        lines = analysis.split('\\n')\n",
    "        in_recommendations_section = False\n",
    "        \n",
    "        for line in lines:\n",
    "            if \"recommendation\" in line.lower() or \"approach\" in line.lower() or \"suggest\" in line.lower():\n",
    "                in_recommendations_section = True\n",
    "                continue\n",
    "                \n",
    "            if in_recommendations_section and line.strip() == \"\":\n",
    "                in_recommendations_section = False\n",
    "                continue\n",
    "                \n",
    "            if in_recommendations_section and line.strip():\n",
    "                # Clean up bullet points and numbering\n",
    "                clean_line = line.strip()\n",
    "                for prefix in ['-', 'â€¢', '*', 'â—‹', 'âž¢', 'â†’']:\n",
    "                    if clean_line.startswith(prefix):\n",
    "                        clean_line = clean_line[1:].strip()\n",
    "                        \n",
    "                # Remove numbering like \"1.\" or \"1)\"\n",
    "                if clean_line and clean_line[0].isdigit() and clean_line[1:3] in ['. ', ') ']:\n",
    "                    clean_line = clean_line[3:].strip()\n",
    "                    \n",
    "                if clean_line:\n",
    "                    recommendations.append(clean_line)\n",
    "        \n",
    "        # If we couldn't extract structured recommendations, do a simpler extraction\n",
    "        if not recommendations:\n",
    "            recommendations = [line.strip() for line in analysis.split('\\n') \n",
    "                           if \"recommend\" in line.lower() or \"should\" in line.lower() or \"must\" in line.lower()]\n",
    "        \n",
    "        return recommendations[:5]  # Limit to top 5 recommendations\n",
    "\n",
    "# Create domain experts\n",
    "async def setup_domain_experts(llm_config: LLMConfig) -> Dict[str, DomainExpert]:\n",
    "    \"\"\"Setup all domain experts\"\"\"\n",
    "    mechanical_expert = DomainExpert(DomainType.MECHANICAL, llm_config)\n",
    "    electrical_expert = DomainExpert(DomainType.ELECTRICAL, llm_config) \n",
    "    programming_expert = DomainExpert(DomainType.PROGRAMMING, llm_config)\n",
    "    \n",
    "    return {\n",
    "        \"mechanical\": mechanical_expert,\n",
    "        \"electrical\": electrical_expert,\n",
    "        \"programming\": programming_expert\n",
    "    }\n",
    "\n",
    "print(\"âœ… Domain experts implementation with prompt saving ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ede6c0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Domain integration system ready!\n"
     ]
    }
   ],
   "source": [
    "# Domain Integration System\n",
    "class DomainIntegrator:\n",
    "    \"\"\"System for integrating analyses across domains\"\"\"\n",
    "    \n",
    "    def __init__(self, llm_config: LLMConfig):\n",
    "        self.llm = llm_config.get_langchain_llm()\n",
    "    \n",
    "    async def integrate_domain_analyses(\n",
    "        self, \n",
    "        user_query: str,\n",
    "        domain_outputs: Dict[str, DomainExpertOutput]\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"Integrate analyses from different domains\"\"\"\n",
    "        \n",
    "        prompt_template = ChatPromptTemplate.from_messages([\n",
    "            SystemMessage(content=\"\"\"You are an expert engineering integration specialist who understands \n",
    "            mechanical, electrical, and software engineering deeply.\n",
    "            \n",
    "            Your task is to analyze separate domain-specific assessments and identify:\n",
    "            1. Areas of compatibility and alignment between domains\n",
    "            2. Potential conflicts or contradictions between domains\n",
    "            3. Integration challenges that must be addressed\n",
    "            4. Cross-domain risks and dependencies\n",
    "            5. Unified recommendations that satisfy all domains\n",
    "            \n",
    "            Provide a balanced perspective that respects the expertise of each domain\n",
    "            while finding optimal integration solutions.\"\"\"),\n",
    "            \n",
    "            HumanMessage(content=f\"\"\"\n",
    "            Analyze these domain-specific assessments for the following project:\n",
    "            \n",
    "            USER REQUIREMENT:\n",
    "            {user_query}\n",
    "            \n",
    "            MECHANICAL ENGINEERING ASSESSMENT:\n",
    "            {domain_outputs[\"mechanical\"].analysis if \"mechanical\" in domain_outputs else \"No mechanical assessment provided\"}\n",
    "            \n",
    "            ELECTRICAL ENGINEERING ASSESSMENT:\n",
    "            {domain_outputs[\"electrical\"].analysis if \"electrical\" in domain_outputs else \"No electrical assessment provided\"}\n",
    "            \n",
    "            SOFTWARE ENGINEERING ASSESSMENT:\n",
    "            {domain_outputs[\"programming\"].analysis if \"programming\" in domain_outputs else \"No software assessment provided\"}\n",
    "            \n",
    "            Create a comprehensive integration analysis that:\n",
    "            1. Identifies cross-domain compatibility issues\n",
    "            2. Highlights contradictions between domain recommendations\n",
    "            3. Provides a unified set of recommendations that satisfies requirements from all domains\n",
    "            4. Suggests any necessary trade-offs or compromises\n",
    "            \n",
    "            Format your response to clearly address cross-domain integration.\n",
    "            \"\"\")\n",
    "        ])\n",
    "        \n",
    "        chain = LLMChain(llm=self.llm, prompt=prompt_template)\n",
    "        \n",
    "        result = await chain.ainvoke({})\n",
    "        integration_analysis = result['text'] if isinstance(result, dict) and 'text' in result else str(result)\n",
    "        \n",
    "        # Build integration report\n",
    "        integration_report = {\n",
    "            \"integration_analysis\": integration_analysis,\n",
    "            \"cross_domain_issues\": self._extract_cross_domain_issues(integration_analysis),\n",
    "            \"unified_recommendations\": self._extract_unified_recommendations(integration_analysis),\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        return integration_report\n",
    "    \n",
    "    def _extract_cross_domain_issues(self, analysis: str) -> List[str]:\n",
    "        \"\"\"Extract cross-domain issues from integration analysis\"\"\"\n",
    "        issues = []\n",
    "        lines = analysis.split('\\n')\n",
    "        in_issues_section = False\n",
    "        \n",
    "        for line in lines:\n",
    "            if any(phrase in line.lower() for phrase in [\"cross-domain issue\", \"conflict\", \"contradiction\", \"integration challenge\"]):\n",
    "                in_issues_section = True\n",
    "                continue\n",
    "                \n",
    "            if in_issues_section and (line.strip() == \"\" or any(phrase in line.lower() for phrase in [\"recommendation\", \"conclusion\"])):\n",
    "                in_issues_section = False\n",
    "                continue\n",
    "                \n",
    "            if in_issues_section and line.strip():\n",
    "                clean_line = self._clean_bullet_point(line)\n",
    "                if clean_line:\n",
    "                    issues.append(clean_line)\n",
    "        \n",
    "        # If we couldn't extract structured issues, do a simpler extraction\n",
    "        if not issues:\n",
    "            issues = [line.strip() for line in analysis.split('\\n')\n",
    "                      if any(phrase in line.lower() for phrase in [\"conflict\", \"contradiction\", \"issue\"])]\n",
    "        \n",
    "        return issues[:7]  # Limit to top 7 issues\n",
    "    \n",
    "    def _extract_unified_recommendations(self, analysis: str) -> List[str]:\n",
    "        \"\"\"Extract unified recommendations from integration analysis\"\"\"\n",
    "        recommendations = []\n",
    "        lines = analysis.split('\\n')\n",
    "        in_recommendations_section = False\n",
    "        \n",
    "        for line in lines:\n",
    "            if any(phrase in line.lower() for phrase in [\"unified recommendation\", \"integrated approach\"]):\n",
    "                in_recommendations_section = True\n",
    "                continue\n",
    "                \n",
    "            if in_recommendations_section and line.strip() == \"\":\n",
    "                in_recommendations_section = False\n",
    "                continue\n",
    "                \n",
    "            if in_recommendations_section and line.strip():\n",
    "                clean_line = self._clean_bullet_point(line)\n",
    "                if clean_line:\n",
    "                    recommendations.append(clean_line)\n",
    "        \n",
    "        # If we couldn't extract structured recommendations, do a simpler extraction\n",
    "        if not recommendations:\n",
    "            recommendations = [line.strip() for line in analysis.split('\\n')\n",
    "                           if any(phrase in line.lower() for phrase in [\"recommend\", \"should\", \"approach\"])]\n",
    "        \n",
    "        return recommendations[:7]  # Limit to top 7 recommendations\n",
    "    \n",
    "    def _clean_bullet_point(self, line: str) -> str:\n",
    "        \"\"\"Clean up bullet points and numbering from a line\"\"\"\n",
    "        clean_line = line.strip()\n",
    "        \n",
    "        for prefix in ['-', 'â€¢', '*', 'â—‹', 'âž¢', 'â†’']:\n",
    "            if clean_line.startswith(prefix):\n",
    "                clean_line = clean_line[1:].strip()\n",
    "                \n",
    "        # Remove numbering like \"1.\" or \"1)\"\n",
    "        if clean_line and clean_line[0].isdigit() and len(clean_line) > 2:\n",
    "            if clean_line[1:3] in ['. ', ') ']:\n",
    "                clean_line = clean_line[3:].strip()\n",
    "                \n",
    "        return clean_line\n",
    "\n",
    "print(\"âœ… Domain integration system ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ceecb32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent prompt generator with workflow integration ready!\n"
     ]
    }
   ],
   "source": [
    "# Agent Prompt Generator with Workflow Integration\n",
    "class AgentPromptGenerator:\n",
    "    \"\"\"Generates specialized prompts for different agents with workflow context\"\"\"\n",
    "    \n",
    "    def __init__(self, llm_config: LLMConfig):\n",
    "        self.llm = llm_config.get_langchain_llm()\n",
    "    \n",
    "    async def generate_agent_prompt(\n",
    "        self,\n",
    "        agent_type: AgentType,\n",
    "        user_query: str,\n",
    "        workflow_manager: WorkflowManager,\n",
    "        step_id: str,\n",
    "        domain_prompts: Dict[str, str],\n",
    "        integration_report: Dict[str, Any],\n",
    "        specific_instructions: Optional[str] = None\n",
    "    ) -> GeneratedPrompt:\n",
    "        \"\"\"Generate specialized prompt for specific agent type with workflow context\"\"\"\n",
    "        \n",
    "        # Get accumulated context from workflow\n",
    "        accumulated_prompt = workflow_manager.get_accumulated_prompt(step_id, domain_prompts)\n",
    "        \n",
    "        # Get agent-specific system instructions\n",
    "        system_instruction = self._get_agent_system_instruction(agent_type)\n",
    "        \n",
    "        # Integration insights\n",
    "        integration_insights = f\"\"\"\n",
    "CROSS-DOMAIN INTEGRATION INSIGHTS:\n",
    "{integration_report['integration_analysis'][:500]}...\n",
    "\n",
    "Key integration issues: {', '.join(integration_report['cross_domain_issues'][:3])}\n",
    "Unified recommendations: {', '.join(integration_report['unified_recommendations'][:3])}\n",
    "\"\"\"\n",
    "        \n",
    "        # Create the comprehensive prompt\n",
    "        instructions_section = f\"SPECIFIC INSTRUCTIONS FOR THIS AGENT:\\n{specific_instructions}\" if specific_instructions else \"\"\n",
    "        \n",
    "        agent_prompt_content = f\"\"\"\n",
    "{system_instruction}\n",
    "\n",
    "ORIGINAL USER REQUEST:\n",
    "{user_query}\n",
    "\n",
    "{accumulated_prompt}\n",
    "\n",
    "{integration_insights}\n",
    "\n",
    "{instructions_section}\n",
    "\n",
    "TASK:\n",
    "Based on all the above context and analyses, create content that addresses the user's original request.\n",
    "Incorporate insights from all domain experts and previous agent work to create a comprehensive output.\n",
    "Ensure your output builds upon and complements the work done by previous agents in the workflow.\n",
    "\"\"\"\n",
    "        \n",
    "        # Generate enhanced prompt using LLM\n",
    "        prompt_template = ChatPromptTemplate.from_messages([\n",
    "            SystemMessage(content=f\"\"\"You are a prompt engineering specialist for {agent_type.value} creation.\n",
    "            Create an optimized prompt for a specialized {agent_type.value} generation agent that incorporates\n",
    "            all the provided context and produces the best possible {agent_type.value}.\"\"\"),\n",
    "            \n",
    "            HumanMessage(content=agent_prompt_content)\n",
    "        ])\n",
    "        \n",
    "        chain = LLMChain(llm=self.llm, prompt=prompt_template)\n",
    "        result = await chain.ainvoke({})\n",
    "        \n",
    "        enhanced_prompt = result['text'] if isinstance(result, dict) and 'text' in result else str(result)\n",
    "        \n",
    "        # Create the generated prompt object\n",
    "        generated_prompt = GeneratedPrompt(\n",
    "            prompt_type=\"agent\",\n",
    "            agent_name=agent_type.value,\n",
    "            prompt_content=enhanced_prompt,\n",
    "            timestamp=datetime.now().isoformat()\n",
    "        )\n",
    "        \n",
    "        return generated_prompt\n",
    "    \n",
    "    def _get_agent_system_instruction(self, agent_type: AgentType) -> str:\n",
    "        \"\"\"Get system instruction specific to agent type\"\"\"\n",
    "        if agent_type == AgentType.DIAGRAM:\n",
    "            return \"\"\"AGENT TYPE: ARCHITECTURE DIAGRAM GENERATOR\n",
    "\n",
    "You specialize in creating technical and architectural diagrams. Your output should be:\n",
    "- Clear visual representations of systems and relationships\n",
    "- Appropriate diagram types (UML, flowcharts, system architecture, etc.)\n",
    "- Proper notation and symbols\n",
    "- Clear component relationships and data flows\n",
    "- Scalable and maintainable design representations\n",
    "\n",
    "Focus on translating complex technical requirements into visual diagrams that communicate \n",
    "the system architecture, component interactions, and design decisions effectively.\"\"\"\n",
    "            \n",
    "        elif agent_type == AgentType.PRESENTATION:\n",
    "            return \"\"\"AGENT TYPE: PRESENTATION GENERATOR\n",
    "\n",
    "You specialize in creating PowerPoint presentations. Your output should include:\n",
    "- Well-structured slide layouts with clear narrative flow\n",
    "- Executive summary and key takeaways\n",
    "- Technical details appropriate for the audience\n",
    "- Visual elements and data visualizations\n",
    "- Compelling storytelling that explains the solution\n",
    "- Action items and next steps\n",
    "\n",
    "Focus on creating presentations that effectively communicate technical solutions \n",
    "to stakeholders while maintaining engagement and clarity.\"\"\"\n",
    "            \n",
    "        elif agent_type == AgentType.DOCUMENT:\n",
    "            return \"\"\"AGENT TYPE: TECHNICAL DOCUMENT GENERATOR\n",
    "\n",
    "You specialize in creating comprehensive technical documentation. Your output should include:\n",
    "- Structured document layout with proper sections\n",
    "- Detailed technical specifications\n",
    "- Implementation guidelines and best practices\n",
    "- Risk assessments and mitigation strategies\n",
    "- Requirements traceability\n",
    "- Professional formatting and readability\n",
    "\n",
    "Focus on creating documents that serve as complete references for technical \n",
    "implementation and decision-making.\"\"\"\n",
    "            \n",
    "        elif agent_type == AgentType.PDF:\n",
    "            return \"\"\"AGENT TYPE: PDF REPORT GENERATOR\n",
    "\n",
    "You specialize in creating professional PDF reports. Your output should include:\n",
    "- Executive summary for decision-makers\n",
    "- Detailed technical analysis and findings\n",
    "- Data visualizations and charts\n",
    "- Recommendations and action plans\n",
    "- Appendices with supporting information\n",
    "- Professional layout and formatting\n",
    "\n",
    "Focus on creating comprehensive reports that combine technical depth \n",
    "with executive-level clarity and visual appeal.\"\"\"\n",
    "            \n",
    "        elif agent_type == AgentType.CODE:\n",
    "            return \"\"\"AGENT TYPE: CODE GENERATOR\n",
    "\n",
    "You specialize in generating implementation code. Your output should include:\n",
    "- Clean, well-documented code following best practices\n",
    "- Appropriate architecture patterns and design principles\n",
    "- Error handling and validation\n",
    "- Unit tests and integration examples\n",
    "- Configuration files and deployment scripts\n",
    "- Documentation and README files\n",
    "\n",
    "Focus on creating production-ready code that implements the technical \n",
    "requirements while being maintainable and scalable.\"\"\"\n",
    "            \n",
    "        else:\n",
    "            return f\"\"\"AGENT TYPE: {agent_type.value.upper()} GENERATOR\n",
    "\n",
    "You specialize in creating {agent_type.value} content. Focus on delivering high-quality \n",
    "output that meets the user's requirements while incorporating insights from domain experts.\"\"\"\n",
    "\n",
    "print(\"âœ… Agent prompt generator with workflow integration ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "23183607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent function mapping ready!\n"
     ]
    }
   ],
   "source": [
    "# Mock External Agent Functions\n",
    "# In a real implementation, these would call your external agent functions\n",
    "\n",
    "async def call_diagram_agent(prompt: str) -> AgentOutput:\n",
    "    \"\"\"Call external diagram generation agent\"\"\"\n",
    "    print(f\"ðŸ”„ Calling external diagram agent with prompt length: {len(prompt)}\")\n",
    "    await asyncio.sleep(1)  # Simulate processing time\n",
    "    \n",
    "    return AgentOutput(\n",
    "        agent_type=AgentType.DIAGRAM.value,\n",
    "        content=\"[Generated architecture diagram with component relationships]\",\n",
    "        format=\"png\",\n",
    "        file_path=\"./data/generated_diagram.png\",\n",
    "        execution_time=1.0\n",
    "    )\n",
    "\n",
    "async def call_presentation_agent(prompt: str) -> AgentOutput:\n",
    "    \"\"\"Call external PowerPoint generation agent\"\"\"\n",
    "    print(f\"ðŸ”„ Calling external presentation agent with prompt length: {len(prompt)}\")\n",
    "    await asyncio.sleep(1.5)  # Simulate processing time\n",
    "    \n",
    "    return AgentOutput(\n",
    "        agent_type=AgentType.PRESENTATION.value,\n",
    "        content=\"[Generated PowerPoint presentation with 12 slides]\",\n",
    "        format=\"pptx\",\n",
    "        file_path=\"./data/generated_presentation.pptx\",\n",
    "        execution_time=1.5\n",
    "    )\n",
    "\n",
    "async def call_document_agent(prompt: str) -> AgentOutput:\n",
    "    \"\"\"Call external document generation agent\"\"\"\n",
    "    print(f\"ðŸ”„ Calling external document agent with prompt length: {len(prompt)}\")\n",
    "    await asyncio.sleep(1.2)  # Simulate processing time\n",
    "    \n",
    "    return AgentOutput(\n",
    "        agent_type=AgentType.DOCUMENT.value,\n",
    "        content=\"[Generated Word document with technical specifications]\",\n",
    "        format=\"docx\",\n",
    "        file_path=\"./data/generated_document.docx\",\n",
    "        execution_time=1.2\n",
    "    )\n",
    "\n",
    "async def call_pdf_agent(prompt: str) -> AgentOutput:\n",
    "    \"\"\"Call external PDF generation agent\"\"\"\n",
    "    print(f\"ðŸ”„ Calling external PDF agent with prompt length: {len(prompt)}\")\n",
    "    await asyncio.sleep(1.3)  # Simulate processing time\n",
    "    \n",
    "    return AgentOutput(\n",
    "        agent_type=AgentType.PDF.value,\n",
    "        content=\"[Generated PDF report with data visualizations]\",\n",
    "        format=\"pdf\",\n",
    "        file_path=\"./data/generated_report.pdf\",\n",
    "        execution_time=1.3\n",
    "    )\n",
    "\n",
    "async def call_code_agent(prompt: str) -> AgentOutput:\n",
    "    \"\"\"Call external code generation agent\"\"\"\n",
    "    print(f\"ðŸ”„ Calling external code agent with prompt length: {len(prompt)}\")\n",
    "    await asyncio.sleep(1.4)  # Simulate processing time\n",
    "    \n",
    "    return AgentOutput(\n",
    "        agent_type=AgentType.CODE.value,\n",
    "        content=\"[Generated code repository with implementation]\",\n",
    "        format=\"zip\",\n",
    "        file_path=\"./data/generated_code.zip\",\n",
    "        execution_time=1.4\n",
    "    )\n",
    "\n",
    "# Agent execution function map\n",
    "AGENT_FUNCTION_MAP = {\n",
    "    AgentType.DIAGRAM.value: call_diagram_agent,\n",
    "    AgentType.PRESENTATION.value: call_presentation_agent,\n",
    "    AgentType.DOCUMENT.value: call_document_agent,\n",
    "    AgentType.PDF.value: call_pdf_agent,\n",
    "    AgentType.CODE.value: call_code_agent\n",
    "}\n",
    "\n",
    "print(\"âœ… Agent function mapping ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "71bc98c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Multi-domain system orchestrator with sequential workflow ready!\n"
     ]
    }
   ],
   "source": [
    "# Main System Orchestrator with Sequential Workflow\n",
    "class MultiDomainSystem:\n",
    "    \"\"\"Main system for orchestrating multi-domain workflows with sequential agent execution\"\"\"\n",
    "    \n",
    "    def __init__(self, use_mock: bool = True):\n",
    "        # Setup configurations\n",
    "        self.llm_config = LLMConfig(timeout=1500)\n",
    "        self.conversation_id = str(uuid.uuid4())\n",
    "        self.conversation_memory = ConversationBufferMemory(return_messages=True)\n",
    "        self.current_state = None\n",
    "        self.workflow_manager = WorkflowManager(self.conversation_id)\n",
    "        \n",
    "        # Initialize components (will be set up asynchronously)\n",
    "        self.domain_experts = None\n",
    "        self.domain_integrator = DomainIntegrator(self.llm_config)\n",
    "        self.prompt_generator = AgentPromptGenerator(self.llm_config)\n",
    "    \n",
    "    async def setup(self):\n",
    "        \"\"\"Initialize the system components\"\"\"\n",
    "        self.domain_experts = await setup_domain_experts(self.llm_config)\n",
    "        print(\"âœ… Multi-domain system initialized and ready!\")\n",
    "    \n",
    "    async def process_user_query(self, user_query: str, agent_workflow: List[str] = None) -> SystemState:\n",
    "        \"\"\"Process a new user query through the entire system with optional workflow\"\"\"\n",
    "        print(f\"ðŸ”„ Processing user query: {user_query[:100]}{'...' if len(user_query) > 100 else ''}\")\n",
    "        \n",
    "        # Set default workflow if none provided\n",
    "        if agent_workflow is None:\n",
    "            agent_workflow = [\"diagram\", \"presentation\", \"document\", \"pdf\", \"code\"]\n",
    "        \n",
    "        # Create workflow\n",
    "        workflow_steps = self.workflow_manager.create_workflow(agent_workflow)\n",
    "        \n",
    "        # Add to conversation history\n",
    "        self.conversation_memory.chat_memory.add_user_message(user_query)\n",
    "        \n",
    "        # Step 1: Analyze with domain experts and save their prompts\n",
    "        domain_outputs = {}\n",
    "        domain_prompts = {}\n",
    "        generated_prompts = {}\n",
    "        \n",
    "        for domain_name, expert in self.domain_experts.items():\n",
    "            print(f\"ðŸ”„ Analyzing with {domain_name} expert...\")\n",
    "            input_data = DomainExpertInput(\n",
    "                user_query=user_query,\n",
    "                domain_name=domain_name\n",
    "            )\n",
    "            \n",
    "            # Get both output and generated prompt\n",
    "            domain_output, generated_prompt = await expert.analyze(input_data, self.conversation_id)\n",
    "            domain_outputs[domain_name] = domain_output\n",
    "            domain_prompts[domain_name] = generated_prompt.prompt_content\n",
    "            generated_prompts[f\"{domain_name}_domain\"] = generated_prompt\n",
    "            \n",
    "            print(f\"âœ… {domain_name.capitalize()} analysis complete - prompt saved\")\n",
    "        \n",
    "        # Step 2: Integrate domain analyses\n",
    "        print(\"ðŸ”„ Integrating domain analyses...\")\n",
    "        integration_report = await self.domain_integrator.integrate_domain_analyses(\n",
    "            user_query, domain_outputs\n",
    "        )\n",
    "        print(\"âœ… Domain integration complete\")\n",
    "        \n",
    "        # Step 3: Save domain outputs and integration to JSON\n",
    "        output_files = {}\n",
    "        for domain, output in domain_outputs.items():\n",
    "            file_path = f\"./data/{domain}_analysis_{self.conversation_id[:8]}.json\"\n",
    "            with open(file_path, 'w') as f:\n",
    "                json.dump(asdict(output), f, indent=2)\n",
    "            output_files[domain] = file_path\n",
    "        \n",
    "        integration_file = f\"./data/integration_{self.conversation_id[:8]}.json\"\n",
    "        with open(integration_file, 'w') as f:\n",
    "            json.dump(integration_report, f, indent=2)\n",
    "        output_files[\"integration\"] = integration_file\n",
    "        \n",
    "        # Create and save system state\n",
    "        conversation_history = [{\n",
    "            \"role\": msg.type,\n",
    "            \"content\": msg.content\n",
    "        } for msg in self.conversation_memory.chat_memory.messages]\n",
    "        \n",
    "        self.current_state = SystemState(\n",
    "            conversation_id=self.conversation_id,\n",
    "            user_query=user_query,\n",
    "            domain_outputs=domain_outputs,\n",
    "            agent_outputs={},\n",
    "            conversation_history=conversation_history,\n",
    "            generated_prompts=generated_prompts,\n",
    "            workflow_steps=workflow_steps,\n",
    "            last_updated=datetime.now().isoformat()\n",
    "        )\n",
    "        \n",
    "        # Store domain prompts and integration report for workflow\n",
    "        self.domain_prompts = domain_prompts\n",
    "        self.integration_report = integration_report\n",
    "        \n",
    "        # Save system state\n",
    "        state_file = self.current_state.save_to_json()\n",
    "        print(f\"âœ… System state saved to {state_file}\")\n",
    "        print(f\"âœ… Workflow created with {len(agent_workflow)} agents: {', '.join(agent_workflow)}\")\n",
    "        \n",
    "        # Add summary to conversation\n",
    "        summary = f\"I've analyzed your request across mechanical, electrical, and programming domains and created a workflow for {len(agent_workflow)} agents.\"\n",
    "        self.conversation_memory.chat_memory.add_ai_message(summary)\n",
    "        \n",
    "        return self.current_state\n",
    "    \n",
    "    async def execute_workflow_step(self, step_id: str, specific_instructions: Optional[str] = None) -> AgentOutput:\n",
    "        \"\"\"Execute a specific workflow step\"\"\"\n",
    "        if self.current_state is None:\n",
    "            raise ValueError(\"No active query to process. Please submit a user query first.\")\n",
    "        \n",
    "        if step_id not in self.workflow_manager.workflow_steps:\n",
    "            raise ValueError(f\"Unknown step ID: {step_id}\")\n",
    "        \n",
    "        step = self.workflow_manager.workflow_steps[step_id]\n",
    "        agent_type = step.agent_type\n",
    "        \n",
    "        print(f\"ðŸš€ Executing workflow step: {step_id} ({agent_type})\")\n",
    "        \n",
    "        # Generate agent-specific prompt using workflow context\n",
    "        agent_enum_type = next(at for at in AgentType if at.value == agent_type)\n",
    "        generated_prompt = await self.prompt_generator.generate_agent_prompt(\n",
    "            agent_type=agent_enum_type,\n",
    "            user_query=self.current_state.user_query,\n",
    "            workflow_manager=self.workflow_manager,\n",
    "            step_id=step_id,\n",
    "            domain_prompts=self.domain_prompts,\n",
    "            integration_report=self.integration_report,\n",
    "            specific_instructions=specific_instructions\n",
    "        )\n",
    "        \n",
    "        # Save the generated prompt to workflow and system state\n",
    "        self.workflow_manager.update_step_prompt(step_id, generated_prompt)\n",
    "        self.current_state.generated_prompts[f\"{agent_type}_agent\"] = generated_prompt\n",
    "        \n",
    "        # Save prompt to file\n",
    "        prompt_filename = f\"{agent_type}_prompt_{self.conversation_id[:8]}.txt\"\n",
    "        prompt_file_path = f\"./data/{prompt_filename}\"\n",
    "        with open(prompt_file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"# {agent_type.upper()} AGENT PROMPT\\n\")\n",
    "            f.write(f\"# Generated: {generated_prompt.timestamp}\\n\")\n",
    "            f.write(f\"# Step ID: {step_id}\\n\\n\")\n",
    "            f.write(generated_prompt.prompt_content)\n",
    "        \n",
    "        generated_prompt.file_path = prompt_file_path\n",
    "        \n",
    "        # Call the appropriate agent function\n",
    "        agent_function = AGENT_FUNCTION_MAP.get(agent_type)\n",
    "        \n",
    "        if agent_function:\n",
    "            agent_output = await agent_function(generated_prompt.prompt_content)\n",
    "            \n",
    "            # Update workflow step and system state\n",
    "            self.workflow_manager.mark_step_executed(step_id, agent_output)\n",
    "            self.current_state.agent_outputs[agent_type] = agent_output\n",
    "            self.current_state.workflow_steps = self.workflow_manager.workflow_steps\n",
    "            self.current_state.save_to_json()\n",
    "            \n",
    "            # Add to conversation\n",
    "            self.conversation_memory.chat_memory.add_ai_message(\n",
    "                f\"I've completed the {agent_type} step in the workflow.\"\n",
    "            )\n",
    "            \n",
    "            print(f\"âœ… {agent_type.capitalize()} step complete - prompt and output saved\")\n",
    "            return agent_output\n",
    "        else:\n",
    "            raise ValueError(f\"No implementation found for agent type: {agent_type}\")\n",
    "    \n",
    "    async def execute_full_workflow(self) -> Dict[str, AgentOutput]:\n",
    "        \"\"\"Execute all steps in the workflow sequentially\"\"\"\n",
    "        if self.current_state is None:\n",
    "            raise ValueError(\"No active query to process. Please submit a user query first.\")\n",
    "        \n",
    "        print(\"ðŸš€ Executing full workflow...\")\n",
    "        all_outputs = {}\n",
    "        \n",
    "        for i, agent_type in enumerate(self.workflow_manager.execution_order):\n",
    "            step_id = f\"step_{i+1}_{agent_type}\"\n",
    "            \n",
    "            if not self.workflow_manager.workflow_steps[step_id].executed:\n",
    "                output = await self.execute_workflow_step(step_id)\n",
    "                all_outputs[agent_type] = output\n",
    "            else:\n",
    "                print(f\"â­ï¸ Skipping already executed step: {step_id}\")\n",
    "                all_outputs[agent_type] = self.workflow_manager.workflow_steps[step_id].output\n",
    "        \n",
    "        print(\"âœ… Full workflow execution complete!\")\n",
    "        return all_outputs\n",
    "    \n",
    "    async def modify_step_prompt(\n",
    "        self,\n",
    "        step_id: str,\n",
    "        user_feedback: str\n",
    "    ) -> Dict[str, AgentOutput]:\n",
    "        \"\"\"Modify a step's prompt and re-execute it and all subsequent steps\"\"\"\n",
    "        if self.current_state is None:\n",
    "            raise ValueError(\"No active query to process. Please submit a user query first.\")\n",
    "        \n",
    "        if step_id not in self.workflow_manager.workflow_steps:\n",
    "            raise ValueError(f\"Unknown step ID: {step_id}\")\n",
    "        \n",
    "        print(f\"ðŸ”„ Modifying step {step_id} based on feedback...\")\n",
    "        \n",
    "        # Get steps that need to be redone\n",
    "        steps_to_redo = self.workflow_manager.get_steps_to_redo(step_id)\n",
    "        print(f\"ðŸ“ Steps to redo: {', '.join(steps_to_redo)}\")\n",
    "        \n",
    "        # Reset the steps\n",
    "        self.workflow_manager.reset_steps(steps_to_redo)\n",
    "        \n",
    "        # Add feedback to conversation history\n",
    "        self.conversation_memory.chat_memory.add_user_message(\n",
    "            f\"Feedback for {step_id}: {user_feedback}\"\n",
    "        )\n",
    "        \n",
    "        # Re-execute the modified step and all subsequent steps\n",
    "        all_outputs = {}\n",
    "        for step_id_to_redo in steps_to_redo:\n",
    "            step = self.workflow_manager.workflow_steps[step_id_to_redo]\n",
    "            \n",
    "            # Use feedback as specific instructions for the first modified step\n",
    "            specific_instructions = user_feedback if step_id_to_redo == step_id else None\n",
    "            \n",
    "            output = await self.execute_workflow_step(step_id_to_redo, specific_instructions)\n",
    "            all_outputs[step.agent_type] = output\n",
    "        \n",
    "        print(\"âœ… Workflow modification complete!\")\n",
    "        return all_outputs\n",
    "    \n",
    "    def get_workflow_status(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get current workflow status\"\"\"\n",
    "        if not self.workflow_manager.workflow_steps:\n",
    "            return {\"status\": \"No workflow created\"}\n",
    "        \n",
    "        status = {\n",
    "            \"total_steps\": len(self.workflow_manager.workflow_steps),\n",
    "            \"completed_steps\": sum(1 for step in self.workflow_manager.workflow_steps.values() if step.executed),\n",
    "            \"execution_order\": self.workflow_manager.execution_order,\n",
    "            \"steps\": {}\n",
    "        }\n",
    "        \n",
    "        for step_id, step in self.workflow_manager.workflow_steps.items():\n",
    "            status[\"steps\"][step_id] = {\n",
    "                \"agent_type\": step.agent_type,\n",
    "                \"executed\": step.executed,\n",
    "                \"has_prompt\": step.generated_prompt is not None,\n",
    "                \"has_output\": step.output is not None\n",
    "            }\n",
    "        \n",
    "        return status\n",
    "    \n",
    "    def get_all_generated_prompts(self) -> Dict[str, str]:\n",
    "        \"\"\"Get all generated prompts with their file paths\"\"\"\n",
    "        if not self.current_state:\n",
    "            return {}\n",
    "        \n",
    "        prompts_info = {}\n",
    "        for prompt_key, prompt_obj in self.current_state.generated_prompts.items():\n",
    "            prompts_info[prompt_key] = {\n",
    "                \"type\": prompt_obj.prompt_type,\n",
    "                \"agent\": prompt_obj.agent_name,\n",
    "                \"file_path\": prompt_obj.file_path,\n",
    "                \"timestamp\": prompt_obj.timestamp,\n",
    "                \"content_preview\": prompt_obj.prompt_content[:200] + \"...\" if len(prompt_obj.prompt_content) > 200 else prompt_obj.prompt_content\n",
    "            }\n",
    "        \n",
    "        return prompts_info\n",
    "    \n",
    "    def get_conversation_history(self) -> List[Dict[str, str]]:\n",
    "        \"\"\"Get the current conversation history\"\"\"\n",
    "        return [{\n",
    "            \"role\": msg.type,\n",
    "            \"content\": msg.content\n",
    "        } for msg in self.conversation_memory.chat_memory.messages]\n",
    "\n",
    "print(\"âœ… Multi-domain system orchestrator with sequential workflow ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0365ae98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Setting up multi-domain system with sequential workflow...\n",
      "âœ… Multi-domain system initialized and ready!\n",
      "\n",
      "ðŸ§ª TESTING WITH SAMPLE QUERY:\n",
      "\n",
      "    We need to design an autonomous delivery robot for indoor environments like hospitals and offices.\n",
      "    The robot should be able to navigate corridors, avoid obstacles, carry payloads of up to 5kg,\n",
      "    and operate for at least 8 hours on a single charge. It should have a secure compartment\n",
      "    for delivering items and a touchscreen interface for user interaction. The robot needs to\n",
      "    integrate with building systems like elevators and automatic doors.\n",
      "    \n",
      "ðŸ”„ Processing user query: \n",
      "    We need to design an autonomous delivery robot for indoor environments like hospitals and offic...\n",
      "ðŸ”„ Analyzing with mechanical expert...\n",
      "âœ… Mechanical analysis complete - prompt saved\n",
      "ðŸ”„ Analyzing with electrical expert...\n",
      "âœ… Mechanical analysis complete - prompt saved\n",
      "ðŸ”„ Analyzing with electrical expert...\n",
      "âœ… Electrical analysis complete - prompt saved\n",
      "ðŸ”„ Analyzing with programming expert...\n",
      "âœ… Electrical analysis complete - prompt saved\n",
      "ðŸ”„ Analyzing with programming expert...\n",
      "âœ… Programming analysis complete - prompt saved\n",
      "ðŸ”„ Integrating domain analyses...\n",
      "âœ… Programming analysis complete - prompt saved\n",
      "ðŸ”„ Integrating domain analyses...\n",
      "âœ… Domain integration complete\n",
      "âœ… System state saved to ./data/system_state_ddd9cdbf.json\n",
      "âœ… Workflow created with 3 agents: diagram, code, presentation\n",
      "\n",
      "ðŸ“Š WORKFLOW STATUS AFTER SETUP:\n",
      "Total steps: 3\n",
      "Execution order: ['diagram', 'code', 'presentation']\n",
      "\n",
      "ðŸ“ DOMAIN PROMPTS GENERATED:\n",
      "- mechanical_domain: ./data/mechanical_domain_prompt_ddd9cdbf.txt\n",
      "- electrical_domain: ./data/electrical_domain_prompt_ddd9cdbf.txt\n",
      "- programming_domain: ./data/programming_domain_prompt_ddd9cdbf.txt\n",
      "\n",
      "ðŸ§ª TESTING FIRST WORKFLOW STEP (DIAGRAM):\n",
      "ðŸš€ Executing workflow step: step_1_diagram (diagram)\n",
      "âœ… Domain integration complete\n",
      "âœ… System state saved to ./data/system_state_ddd9cdbf.json\n",
      "âœ… Workflow created with 3 agents: diagram, code, presentation\n",
      "\n",
      "ðŸ“Š WORKFLOW STATUS AFTER SETUP:\n",
      "Total steps: 3\n",
      "Execution order: ['diagram', 'code', 'presentation']\n",
      "\n",
      "ðŸ“ DOMAIN PROMPTS GENERATED:\n",
      "- mechanical_domain: ./data/mechanical_domain_prompt_ddd9cdbf.txt\n",
      "- electrical_domain: ./data/electrical_domain_prompt_ddd9cdbf.txt\n",
      "- programming_domain: ./data/programming_domain_prompt_ddd9cdbf.txt\n",
      "\n",
      "ðŸ§ª TESTING FIRST WORKFLOW STEP (DIAGRAM):\n",
      "ðŸš€ Executing workflow step: step_1_diagram (diagram)\n",
      "ðŸ”„ Calling external diagram agent with prompt length: 3400\n",
      "ðŸ”„ Calling external diagram agent with prompt length: 3400\n",
      "âœ… Diagram step complete - prompt and output saved\n",
      "Output: [Generated architecture diagram with component relationships]\n",
      "\n",
      "ðŸ§ª TESTING SECOND WORKFLOW STEP (CODE):\n",
      "ðŸš€ Executing workflow step: step_2_code (code)\n",
      "âœ… Diagram step complete - prompt and output saved\n",
      "Output: [Generated architecture diagram with component relationships]\n",
      "\n",
      "ðŸ§ª TESTING SECOND WORKFLOW STEP (CODE):\n",
      "ðŸš€ Executing workflow step: step_2_code (code)\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[165], line 69\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m system\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Run the test\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m test_system \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m setup_and_test_workflow()\n",
      "Cell \u001b[1;32mIn[165], line 45\u001b[0m, in \u001b[0;36msetup_and_test_workflow\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸ§ª TESTING SECOND WORKFLOW STEP (CODE):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m step_2_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep_2_code\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 45\u001b[0m code_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m system\u001b[38;5;241m.\u001b[39mexecute_workflow_step(step_2_id)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcode_output\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Test feedback and modification\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[164], line 124\u001b[0m, in \u001b[0;36mMultiDomainSystem.execute_workflow_step\u001b[1;34m(self, step_id, specific_instructions)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# Generate agent-specific prompt using workflow context\u001b[39;00m\n\u001b[0;32m    123\u001b[0m agent_enum_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(at \u001b[38;5;28;01mfor\u001b[39;00m at \u001b[38;5;129;01min\u001b[39;00m AgentType \u001b[38;5;28;01mif\u001b[39;00m at\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m agent_type)\n\u001b[1;32m--> 124\u001b[0m generated_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt_generator\u001b[38;5;241m.\u001b[39mgenerate_agent_prompt(\n\u001b[0;32m    125\u001b[0m     agent_type\u001b[38;5;241m=\u001b[39magent_enum_type,\n\u001b[0;32m    126\u001b[0m     user_query\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_state\u001b[38;5;241m.\u001b[39muser_query,\n\u001b[0;32m    127\u001b[0m     workflow_manager\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkflow_manager,\n\u001b[0;32m    128\u001b[0m     step_id\u001b[38;5;241m=\u001b[39mstep_id,\n\u001b[0;32m    129\u001b[0m     domain_prompts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain_prompts,\n\u001b[0;32m    130\u001b[0m     integration_report\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintegration_report,\n\u001b[0;32m    131\u001b[0m     specific_instructions\u001b[38;5;241m=\u001b[39mspecific_instructions\n\u001b[0;32m    132\u001b[0m )\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# Save the generated prompt to workflow and system state\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkflow_manager\u001b[38;5;241m.\u001b[39mupdate_step_prompt(step_id, generated_prompt)\n",
      "Cell \u001b[1;32mIn[162], line 66\u001b[0m, in \u001b[0;36mAgentPromptGenerator.generate_agent_prompt\u001b[1;34m(self, agent_type, user_query, workflow_manager, step_id, domain_prompts, integration_report, specific_instructions)\u001b[0m\n\u001b[0;32m     57\u001b[0m prompt_template \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages([\n\u001b[0;32m     58\u001b[0m     SystemMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mYou are a prompt engineering specialist for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent_type\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m creation.\u001b[39m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;124m    Create an optimized prompt for a specialized \u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent_type\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m generation agent that incorporates\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     62\u001b[0m     HumanMessage(content\u001b[38;5;241m=\u001b[39magent_prompt_content)\n\u001b[0;32m     63\u001b[0m ])\n\u001b[0;32m     65\u001b[0m chain \u001b[38;5;241m=\u001b[39m LLMChain(llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, prompt\u001b[38;5;241m=\u001b[39mprompt_template)\n\u001b[1;32m---> 66\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m chain\u001b[38;5;241m.\u001b[39mainvoke({})\n\u001b[0;32m     68\u001b[0m enhanced_prompt \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m result \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(result)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Create the generated prompt object\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\site-packages\\langchain\\chains\\base.py:220\u001b[0m, in \u001b[0;36mChain.ainvoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    219\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 220\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acall(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acall(inputs)\n\u001b[0;32m    223\u001b[0m     )\n\u001b[0;32m    224\u001b[0m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maprep_outputs(\n\u001b[0;32m    225\u001b[0m         inputs,\n\u001b[0;32m    226\u001b[0m         outputs,\n\u001b[0;32m    227\u001b[0m         return_only_outputs,\n\u001b[0;32m    228\u001b[0m     )\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\site-packages\\langchain\\chains\\llm.py:307\u001b[0m, in \u001b[0;36mLLMChain._acall\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_acall\u001b[39m(\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    304\u001b[0m     inputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m    305\u001b[0m     run_manager: Optional[AsyncCallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    306\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 307\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magenerate([inputs], run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\site-packages\\langchain\\chains\\llm.py:166\u001b[0m, in \u001b[0;36mLLMChain.agenerate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m    164\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39magenerate_prompt(\n\u001b[0;32m    167\u001b[0m         prompts,\n\u001b[0;32m    168\u001b[0m         stop,\n\u001b[0;32m    169\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs,\n\u001b[0;32m    171\u001b[0m     )\n\u001b[0;32m    172\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mabatch(\n\u001b[0;32m    173\u001b[0m     cast(\u001b[38;5;28mlist\u001b[39m, prompts),\n\u001b[0;32m    174\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks},\n\u001b[0;32m    175\u001b[0m )\n\u001b[0;32m    176\u001b[0m generations: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[Generation]] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\site-packages\\langchain_core\\language_models\\llms.py:800\u001b[0m, in \u001b[0;36mBaseLLM.agenerate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    791\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21magenerate_prompt\u001b[39m(\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    797\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    798\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    799\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 800\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magenerate(\n\u001b[0;32m    801\u001b[0m         prompt_strings, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    802\u001b[0m     )\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\site-packages\\langchain_core\\language_models\\llms.py:1261\u001b[0m, in \u001b[0;36mBaseLLM.agenerate\u001b[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m   1244\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[0;32m   1245\u001b[0m         \u001b[38;5;241m*\u001b[39m[\n\u001b[0;32m   1246\u001b[0m             callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1258\u001b[0m         ]\n\u001b[0;32m   1259\u001b[0m     )\n\u001b[0;32m   1260\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [r[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m run_managers]  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m-> 1261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agenerate_helper(\n\u001b[0;32m   1262\u001b[0m         prompts,\n\u001b[0;32m   1263\u001b[0m         stop,\n\u001b[0;32m   1264\u001b[0m         run_managers,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1265\u001b[0m         new_arg_supported\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(new_arg_supported),\n\u001b[0;32m   1266\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1267\u001b[0m     )\n\u001b[0;32m   1268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1269\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[0;32m   1270\u001b[0m         \u001b[38;5;241m*\u001b[39m[\n\u001b[0;32m   1271\u001b[0m             callback_managers[idx]\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1280\u001b[0m         ]\n\u001b[0;32m   1281\u001b[0m     )\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\site-packages\\langchain_core\\language_models\\llms.py:1072\u001b[0m, in \u001b[0;36mBaseLLM._agenerate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_agenerate_helper\u001b[39m(\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1063\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1068\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1069\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m   1070\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1071\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1072\u001b[0m             \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agenerate(\n\u001b[0;32m   1073\u001b[0m                 prompts,\n\u001b[0;32m   1074\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m   1075\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1076\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1077\u001b[0m             )\n\u001b[0;32m   1078\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m   1079\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agenerate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[0;32m   1080\u001b[0m         )\n\u001b[0;32m   1081\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;241m*\u001b[39m[\n\u001b[0;32m   1084\u001b[0m                 run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m   1085\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers\n\u001b[0;32m   1086\u001b[0m             ]\n\u001b[0;32m   1087\u001b[0m         )\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\site-packages\\langchain_community\\llms\\ollama.py:469\u001b[0m, in \u001b[0;36mOllama._agenerate\u001b[1;34m(self, prompts, stop, images, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    467\u001b[0m generations \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m--> 469\u001b[0m     final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_astream_with_aggregation(\n\u001b[0;32m    470\u001b[0m         prompt,\n\u001b[0;32m    471\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    472\u001b[0m         images\u001b[38;5;241m=\u001b[39mimages,\n\u001b[0;32m    473\u001b[0m         run_manager\u001b[38;5;241m=\u001b[39mrun_manager,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    474\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    475\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    476\u001b[0m     )\n\u001b[0;32m    477\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([final_chunk])\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\site-packages\\langchain_community\\llms\\ollama.py:375\u001b[0m, in \u001b[0;36m_OllamaCommon._astream_with_aggregation\u001b[1;34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_astream_with_aggregation\u001b[39m(\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    368\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    373\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m GenerationChunk:\n\u001b[0;32m    374\u001b[0m     final_chunk: Optional[GenerationChunk] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 375\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m stream_resp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acreate_generate_stream(prompt, stop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m stream_resp:\n\u001b[0;32m    377\u001b[0m             chunk \u001b[38;5;241m=\u001b[39m _stream_response_to_generation_chunk(stream_resp)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\site-packages\\langchain_community\\llms\\ollama.py:209\u001b[0m, in \u001b[0;36m_OllamaCommon._acreate_generate_stream\u001b[1;34m(self, prompt, stop, images, **kwargs)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_acreate_generate_stream\u001b[39m(\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    203\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    207\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncIterator[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    208\u001b[0m     payload \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m: images}\n\u001b[1;32m--> 209\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acreate_stream(\n\u001b[0;32m    210\u001b[0m         payload\u001b[38;5;241m=\u001b[39mpayload,\n\u001b[0;32m    211\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    212\u001b[0m         api_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/api/generate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    214\u001b[0m     ):\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m item\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\site-packages\\langchain_community\\llms\\ollama.py:337\u001b[0m, in \u001b[0;36m_OllamaCommon._acreate_stream\u001b[1;34m(self, api_url, payload, stop, **kwargs)\u001b[0m\n\u001b[0;32m    332\u001b[0m         optional_detail \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    334\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOllama call failed with status code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    335\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Details: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptional_detail\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    336\u001b[0m         )\n\u001b[1;32m--> 337\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent:\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m line\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\site-packages\\aiohttp\\streams.py:52\u001b[0m, in \u001b[0;36mAsyncStreamIterator.__anext__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__anext__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _T:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         rv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_func()\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m EofStream:\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\site-packages\\aiohttp\\streams.py:352\u001b[0m, in \u001b[0;36mStreamReader.readline\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreadline\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbytes\u001b[39m:\n\u001b[1;32m--> 352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreaduntil()\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\site-packages\\aiohttp\\streams.py:386\u001b[0m, in \u001b[0;36mStreamReader.readuntil\u001b[1;34m(self, separator)\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_enough:\n\u001b[1;32m--> 386\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreaduntil\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m chunk\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\site-packages\\aiohttp\\streams.py:347\u001b[0m, in \u001b[0;36mStreamReader._wait\u001b[1;34m(self, func_name)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timer:\n\u001b[1;32m--> 347\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m waiter\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_waiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Setup and test the sequential workflow system\n",
    "async def setup_and_test_workflow():\n",
    "    \"\"\"Setup and test the multi-domain system with sequential workflow\"\"\"\n",
    "    print(\"ðŸš€ Setting up multi-domain system with sequential workflow...\")\n",
    "    \n",
    "    # Create and initialize system\n",
    "    system = MultiDomainSystem()\n",
    "    await system.setup()\n",
    "    \n",
    "    # Process a test query with custom workflow\n",
    "    test_query = \"\"\"\n",
    "    We need to design an autonomous delivery robot for indoor environments like hospitals and offices.\n",
    "    The robot should be able to navigate corridors, avoid obstacles, carry payloads of up to 5kg,\n",
    "    and operate for at least 8 hours on a single charge. It should have a secure compartment\n",
    "    for delivering items and a touchscreen interface for user interaction. The robot needs to\n",
    "    integrate with building systems like elevators and automatic doors.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nðŸ§ª TESTING WITH SAMPLE QUERY:\")\n",
    "    print(test_query)\n",
    "    \n",
    "    # Process query with custom workflow order\n",
    "    custom_workflow = [\"diagram\", \"code\", \"presentation\"]  # Custom order\n",
    "    state = await system.process_user_query(test_query, custom_workflow)\n",
    "    \n",
    "    print(\"\\nðŸ“Š WORKFLOW STATUS AFTER SETUP:\")\n",
    "    status = system.get_workflow_status()\n",
    "    print(f\"Total steps: {status['total_steps']}\")\n",
    "    print(f\"Execution order: {status['execution_order']}\")\n",
    "    \n",
    "    print(\"\\nðŸ“ DOMAIN PROMPTS GENERATED:\")\n",
    "    for prompt_key, prompt_info in system.get_all_generated_prompts().items():\n",
    "        if prompt_info[\"type\"] == \"domain\":\n",
    "            print(f\"- {prompt_key}: {prompt_info['file_path']}\")\n",
    "    \n",
    "    # Execute first step (diagram)\n",
    "    print(\"\\nðŸ§ª TESTING FIRST WORKFLOW STEP (DIAGRAM):\")\n",
    "    step_1_id = \"step_1_diagram\"\n",
    "    diagram_output = await system.execute_workflow_step(step_1_id)\n",
    "    print(f\"Output: {diagram_output.content}\")\n",
    "    \n",
    "    # Execute second step (code) - this should include diagram prompt in its context\n",
    "    print(\"\\nðŸ§ª TESTING SECOND WORKFLOW STEP (CODE):\")\n",
    "    step_2_id = \"step_2_code\"\n",
    "    code_output = await system.execute_workflow_step(step_2_id)\n",
    "    print(f\"Output: {code_output.content}\")\n",
    "    \n",
    "    # Test feedback and modification\n",
    "    print(\"\\nðŸ§ª TESTING WORKFLOW MODIFICATION:\")\n",
    "    feedback = \"The code should focus more on the safety systems and emergency protocols.\"\n",
    "    modified_outputs = await system.modify_step_prompt(step_2_id, feedback)\n",
    "    \n",
    "    print(f\"Modified outputs: {list(modified_outputs.keys())}\")\n",
    "    \n",
    "    # Show all generated prompts\n",
    "    print(\"\\nðŸ“ ALL GENERATED PROMPTS:\")\n",
    "    all_prompts = system.get_all_generated_prompts()\n",
    "    for prompt_key, prompt_info in all_prompts.items():\n",
    "        print(f\"- {prompt_key} ({prompt_info['type']}): {prompt_info['file_path']}\")\n",
    "    \n",
    "    # Show final workflow status\n",
    "    print(\"\\nðŸ“Š FINAL WORKFLOW STATUS:\")\n",
    "    final_status = system.get_workflow_status()\n",
    "    print(f\"Completed: {final_status['completed_steps']}/{final_status['total_steps']} steps\")\n",
    "    \n",
    "    return system\n",
    "\n",
    "# Run the test\n",
    "test_system = await setup_and_test_workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d7e706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced workflow demonstration\n",
    "async def demonstrate_advanced_workflow():\n",
    "    \"\"\"Demonstrate advanced workflow features with sequential prompt chaining\"\"\"\n",
    "    print(\"ðŸŽ¯ DEMONSTRATING ADVANCED SEQUENTIAL WORKFLOW\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Create fresh system\n",
    "    system = MultiDomainSystem(use_mock=True)\n",
    "    await system.setup()\n",
    "    \n",
    "    # Complex manufacturing query\n",
    "    complex_query = \"\"\"\n",
    "    Our manufacturing company needs a robotic arm system for automating the assembly of electronic devices.\n",
    "    The system should pick components from bins, place them on PCBs with high precision (Â±0.1mm),\n",
    "    and handle soldering operations. We need to control multiple robotic arms in coordination,\n",
    "    monitor the quality of assembly in real-time with computer vision, and integrate with our\n",
    "    existing MES (Manufacturing Execution System). The system should be reconfigurable for different\n",
    "    products with minimal downtime. Safety features are critical since operators will work alongside\n",
    "    the robots. We plan to deploy this system in 5 production lines over the next year.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nðŸ“‹ USER QUERY:\")\n",
    "    print(complex_query)\n",
    "    \n",
    "    # Create workflow with all agents in specific order\n",
    "    full_workflow = [\"diagram\", \"code\", \"document\", \"presentation\", \"pdf\"]\n",
    "    \n",
    "    # Process the query through domain experts\n",
    "    print(\"\\nðŸ§  PROCESSING WITH DOMAIN EXPERTS AND CREATING WORKFLOW...\")\n",
    "    state = await system.process_user_query(complex_query, full_workflow)\n",
    "    \n",
    "    print(\"\\nðŸ“Š DOMAIN ANALYSIS RESULTS:\")\n",
    "    for domain, output in state.domain_outputs.items():\n",
    "        print(f\"\\nâ–¶ï¸ {domain.upper()} DOMAIN:\")\n",
    "        print(f\"  â€¢ Analysis length: {len(output.analysis)} characters\")\n",
    "        print(f\"  â€¢ Key concerns: {output.concerns[:2]}\")\n",
    "        print(f\"  â€¢ Recommendations: {output.recommendations[:2]}\")\n",
    "    \n",
    "    print(\"\\nðŸ“ DOMAIN PROMPTS SAVED:\")\n",
    "    domain_prompts = {k: v for k, v in system.get_all_generated_prompts().items() if \"domain\" in k}\n",
    "    for prompt_key, prompt_info in domain_prompts.items():\n",
    "        print(f\"  â€¢ {prompt_key}: {prompt_info['file_path']}\")\n",
    "    \n",
    "    # Execute workflow step by step to show prompt chaining\n",
    "    print(\"\\n\udd17 EXECUTING WORKFLOW WITH PROMPT CHAINING:\")\n",
    "    \n",
    "    # Step 1: Diagram (uses only domain prompts)\n",
    "    print(\"\\nâ–¶ï¸ STEP 1: DIAGRAM GENERATION\")\n",
    "    step_1 = await system.execute_workflow_step(\"step_1_diagram\")\n",
    "    print(f\"  â€¢ Generated diagram: {step_1.content[:100]}...\")\n",
    "    \n",
    "    # Step 2: Code (uses domain prompts + diagram prompt)\n",
    "    print(\"\\nâ–¶ï¸ STEP 2: CODE GENERATION (includes diagram context)\")\n",
    "    step_2 = await system.execute_workflow_step(\"step_2_code\")\n",
    "    print(f\"  â€¢ Generated code: {step_2.content[:100]}...\")\n",
    "    \n",
    "    # Step 3: Document (uses domain + diagram + code prompts)\n",
    "    print(\"\\nâ–¶ï¸ STEP 3: DOCUMENT GENERATION (includes diagram + code context)\")\n",
    "    step_3 = await system.execute_workflow_step(\"step_3_document\")\n",
    "    print(f\"  â€¢ Generated document: {step_3.content[:100]}...\")\n",
    "    \n",
    "    # Show prompt chaining in action\n",
    "    print(\"\\nðŸ” DEMONSTRATING PROMPT CHAINING:\")\n",
    "    all_prompts = system.get_all_generated_prompts()\n",
    "    agent_prompts = {k: v for k, v in all_prompts.items() if \"agent\" in k}\n",
    "    \n",
    "    for i, (prompt_key, prompt_info) in enumerate(agent_prompts.items(), 1):\n",
    "        print(f\"\\n{i}. {prompt_key.upper()}:\")\n",
    "        print(f\"   File: {prompt_info['file_path']}\")\n",
    "        print(f\"   Preview: {prompt_info['content_preview'][:150]}...\")\n",
    "        \n",
    "        # Show how each prompt builds on previous ones\n",
    "        if i > 1:\n",
    "            print(f\"   ðŸ“Œ This prompt includes context from {i-1} previous step(s)\")\n",
    "    \n",
    "    # Demonstrate modification and cascade effect\n",
    "    print(\"\\nðŸ”„ DEMONSTRATING MODIFICATION CASCADE:\")\n",
    "    feedback = \"\"\"\n",
    "    The code architecture should use a microservices approach instead of monolithic design.\n",
    "    Each robotic arm should be a separate service that can be scaled independently.\n",
    "    Include Docker containerization and Kubernetes orchestration.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ðŸ“ Applying feedback to code step...\")\n",
    "    modified_outputs = await system.modify_step_prompt(\"step_2_code\", feedback)\n",
    "    \n",
    "    print(f\"ðŸ”„ Modified and re-executed steps: {list(modified_outputs.keys())}\")\n",
    "    print(\"ðŸ“Œ Note: All steps after 'code' were automatically re-executed with the new context\")\n",
    "    \n",
    "    # Execute remaining steps\n",
    "    print(\"\\nâ–¶ï¸ COMPLETING REMAINING WORKFLOW STEPS:\")\n",
    "    remaining_outputs = await system.execute_full_workflow()\n",
    "    \n",
    "    print(f\"âœ… All steps completed: {list(remaining_outputs.keys())}\")\n",
    "    \n",
    "    # Show final prompt files\n",
    "    print(\"\\n\udcc1 FINAL GENERATED PROMPT FILES:\")\n",
    "    final_prompts = system.get_all_generated_prompts()\n",
    "    for prompt_key, prompt_info in final_prompts.items():\n",
    "        print(f\"  â€¢ {prompt_key}: {prompt_info['file_path']}\")\n",
    "    \n",
    "    # Show workflow status\n",
    "    print(\"\\nðŸ“Š FINAL WORKFLOW STATUS:\")\n",
    "    final_status = system.get_workflow_status()\n",
    "    print(f\"  â€¢ Total steps: {final_status['total_steps']}\")\n",
    "    print(f\"  â€¢ Completed steps: {final_status['completed_steps']}\")\n",
    "    print(f\"  â€¢ Success rate: {final_status['completed_steps']/final_status['total_steps']*100:.1f}%\")\n",
    "    \n",
    "    print(\"\\nâœ… ADVANCED WORKFLOW DEMONSTRATION COMPLETE\")\n",
    "    print(\"ðŸ”‘ KEY FEATURES DEMONSTRATED:\")\n",
    "    print(\"   â€¢ Sequential prompt chaining (each agent builds on previous)\")\n",
    "    print(\"   â€¢ Automatic prompt saving for all domain and agent interactions\")\n",
    "    print(\"   â€¢ Modification cascade (changing one step updates all subsequent steps)\")\n",
    "    print(\"   â€¢ Comprehensive workflow tracking and status reporting\")\n",
    "\n",
    "# Run the advanced demonstration\n",
    "await demonstrate_advanced_workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "dba917bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“š SYSTEM USAGE GUIDE\n",
      "==================================================\n",
      "\n",
      "ðŸ”§ BASIC USAGE:\n",
      "    \n",
      "    # 1. Create and setup system\n",
      "    system = MultiDomainSystem()\n",
      "    await system.setup()\n",
      "    \n",
      "    # 2. Process query with default workflow\n",
      "    state = await system.process_user_query(\"Your engineering question here\")\n",
      "    \n",
      "    # 3. Execute full workflow\n",
      "    outputs = await system.execute_full_workflow()\n",
      "\n",
      "ðŸ”§ CUSTOM WORKFLOW:\n",
      "    \n",
      "    # Create custom agent order\n",
      "    custom_workflow = [\"code\", \"diagram\", \"presentation\"]  # Code first, then diagram, then presentation\n",
      "    state = await system.process_user_query(\"Your question\", custom_workflow)\n",
      "\n",
      "ðŸ”§ STEP-BY-STEP EXECUTION:\n",
      "    \n",
      "    # Execute individual steps\n",
      "    diagram_output = await system.execute_workflow_step(\"step_1_diagram\")\n",
      "    code_output = await system.execute_workflow_step(\"step_2_code\")\n",
      "    \n",
      "ðŸ”§ MODIFY AND RE-EXECUTE:\n",
      "    \n",
      "    # Modify a step and cascade changes\n",
      "    feedback = \"Make the code more modular with better error handling\"\n",
      "    modified_outputs = await system.modify_step_prompt(\"step_2_code\", feedback)\n",
      "\n",
      "ðŸ”§ CHECK STATUS AND PROMPTS:\n",
      "    \n",
      "    # Get workflow status\n",
      "    status = system.get_workflow_status()\n",
      "    \n",
      "    # Get all generated prompts\n",
      "    prompts = system.get_all_generated_prompts()\n",
      "    \n",
      "    # Get conversation history\n",
      "    history = system.get_conversation_history()\n",
      "\n",
      "\n",
      "ðŸ“ FILE ORGANIZATION:\n",
      "\n",
      "    All outputs are saved in ./data/ directory:\n",
      "    \n",
      "    ðŸ“‚ data/\n",
      "    â”œâ”€â”€ ðŸ“„ mechanical_domain_prompt_[id].txt      # Domain expert prompts\n",
      "    â”œâ”€â”€ ðŸ“„ electrical_domain_prompt_[id].txt\n",
      "    â”œâ”€â”€ ðŸ“„ programming_domain_prompt_[id].txt\n",
      "    â”œâ”€â”€ ðŸ“„ diagram_prompt_[id].txt               # Agent prompts\n",
      "    â”œâ”€â”€ ðŸ“„ code_prompt_[id].txt\n",
      "    â”œâ”€â”€ ðŸ“„ presentation_prompt_[id].txt\n",
      "    â”œâ”€â”€ ðŸ“„ document_prompt_[id].txt\n",
      "    â”œâ”€â”€ ðŸ“„ pdf_prompt_[id].txt\n",
      "    â”œâ”€â”€ ðŸ“„ system_state_[id].json               # Complete system state\n",
      "    â”œâ”€â”€ ðŸ“„ integration_[id].json                # Domain integration report\n",
      "    â””â”€â”€ ðŸ“„ [domain]_analysis_[id].json          # Individual domain analyses\n",
      "    \n",
      "\n",
      "ðŸ”‘ KEY FEATURES:\n",
      "\n",
      "    âœ… Sequential Workflow: Each agent's prompt includes all previous agents' prompts\n",
      "    âœ… Prompt Saving: Every prompt (domain + agent) is automatically saved\n",
      "    âœ… Modification Cascade: Changing one step automatically updates all subsequent steps\n",
      "    âœ… Flexible Ordering: Define custom agent execution order\n",
      "    âœ… State Management: Complete system state is saved and can be restored\n",
      "    âœ… Progress Tracking: Monitor workflow progress and status\n",
      "    \n",
      "\n",
      "âš¡ WORKFLOW BENEFITS:\n",
      "\n",
      "    ðŸ”— Prompt Chaining: Each agent gets context from all previous work\n",
      "    ðŸ“ Complete Traceability: All prompts are saved for audit and debugging  \n",
      "    ðŸ”„ Easy Iteration: Modify any step and automatically update downstream work\n",
      "    ðŸŽ¯ Targeted Output: Each agent builds upon previous work for better results\n",
      "    ðŸ“Š Full Visibility: Track progress and see all generated content\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Usage Examples and System Guide\n",
    "async def show_usage_examples():\n",
    "    \"\"\"Show how to use the enhanced system with all its features\"\"\"\n",
    "    print(\"ðŸ“š SYSTEM USAGE GUIDE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(\"\"\"\n",
    "ðŸ”§ BASIC USAGE:\n",
    "    \n",
    "    # 1. Create and setup system\n",
    "    system = MultiDomainSystem()\n",
    "    await system.setup()\n",
    "    \n",
    "    # 2. Process query with default workflow\n",
    "    state = await system.process_user_query(\"Your engineering question here\")\n",
    "    \n",
    "    # 3. Execute full workflow\n",
    "    outputs = await system.execute_full_workflow()\n",
    "\n",
    "ðŸ”§ CUSTOM WORKFLOW:\n",
    "    \n",
    "    # Create custom agent order\n",
    "    custom_workflow = [\"code\", \"diagram\", \"presentation\"]  # Code first, then diagram, then presentation\n",
    "    state = await system.process_user_query(\"Your question\", custom_workflow)\n",
    "\n",
    "ðŸ”§ STEP-BY-STEP EXECUTION:\n",
    "    \n",
    "    # Execute individual steps\n",
    "    diagram_output = await system.execute_workflow_step(\"step_1_diagram\")\n",
    "    code_output = await system.execute_workflow_step(\"step_2_code\")\n",
    "    \n",
    "ðŸ”§ MODIFY AND RE-EXECUTE:\n",
    "    \n",
    "    # Modify a step and cascade changes\n",
    "    feedback = \"Make the code more modular with better error handling\"\n",
    "    modified_outputs = await system.modify_step_prompt(\"step_2_code\", feedback)\n",
    "\n",
    "ðŸ”§ CHECK STATUS AND PROMPTS:\n",
    "    \n",
    "    # Get workflow status\n",
    "    status = system.get_workflow_status()\n",
    "    \n",
    "    # Get all generated prompts\n",
    "    prompts = system.get_all_generated_prompts()\n",
    "    \n",
    "    # Get conversation history\n",
    "    history = system.get_conversation_history()\n",
    "\"\"\")\n",
    "    \n",
    "    print(\"\\nðŸ“ FILE ORGANIZATION:\")\n",
    "    print(\"\"\"\n",
    "    All outputs are saved in ./data/ directory:\n",
    "    \n",
    "    ðŸ“‚ data/\n",
    "    â”œâ”€â”€ ðŸ“„ mechanical_domain_prompt_[id].txt      # Domain expert prompts\n",
    "    â”œâ”€â”€ ðŸ“„ electrical_domain_prompt_[id].txt\n",
    "    â”œâ”€â”€ ðŸ“„ programming_domain_prompt_[id].txt\n",
    "    â”œâ”€â”€ ðŸ“„ diagram_prompt_[id].txt               # Agent prompts\n",
    "    â”œâ”€â”€ ðŸ“„ code_prompt_[id].txt\n",
    "    â”œâ”€â”€ ðŸ“„ presentation_prompt_[id].txt\n",
    "    â”œâ”€â”€ ðŸ“„ document_prompt_[id].txt\n",
    "    â”œâ”€â”€ ðŸ“„ pdf_prompt_[id].txt\n",
    "    â”œâ”€â”€ ðŸ“„ system_state_[id].json               # Complete system state\n",
    "    â”œâ”€â”€ ðŸ“„ integration_[id].json                # Domain integration report\n",
    "    â””â”€â”€ ðŸ“„ [domain]_analysis_[id].json          # Individual domain analyses\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"\\nðŸ”‘ KEY FEATURES:\")\n",
    "    print(\"\"\"\n",
    "    âœ… Sequential Workflow: Each agent's prompt includes all previous agents' prompts\n",
    "    âœ… Prompt Saving: Every prompt (domain + agent) is automatically saved\n",
    "    âœ… Modification Cascade: Changing one step automatically updates all subsequent steps\n",
    "    âœ… Flexible Ordering: Define custom agent execution order\n",
    "    âœ… State Management: Complete system state is saved and can be restored\n",
    "    âœ… Progress Tracking: Monitor workflow progress and status\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"\\nâš¡ WORKFLOW BENEFITS:\")\n",
    "    print(\"\"\"\n",
    "    ðŸ”— Prompt Chaining: Each agent gets context from all previous work\n",
    "    ðŸ“ Complete Traceability: All prompts are saved for audit and debugging  \n",
    "    ðŸ”„ Easy Iteration: Modify any step and automatically update downstream work\n",
    "    ðŸŽ¯ Targeted Output: Each agent builds upon previous work for better results\n",
    "    ðŸ“Š Full Visibility: Track progress and see all generated content\n",
    "    \"\"\")\n",
    "\n",
    "# Show the usage guide\n",
    "await show_usage_examples()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec092eb",
   "metadata": {},
   "source": [
    "## âœ… System Implementation Complete\n",
    "\n",
    "### ðŸ”„ **Sequential Workflow System**\n",
    "\n",
    "The Multi-Domain System now includes a **sequential workflow** where each agent's prompt is built upon all previous agents' prompts, creating a chain of context that improves the quality of each subsequent output.\n",
    "\n",
    "### ðŸ“ **Prompt Saving System**\n",
    "\n",
    "**Every prompt is automatically saved**:\n",
    "- **Domain Expert Prompts**: Saved for mechanical, electrical, and programming analyses\n",
    "- **Agent Prompts**: Saved for each agent (diagram, code, presentation, document, PDF)\n",
    "- **File Organization**: All prompts stored in `./data/` with timestamps and unique IDs\n",
    "\n",
    "### ðŸ”— **Workflow Chaining Logic**\n",
    "\n",
    "1. **Domain Analysis**: Each domain expert analyzes the user query and saves its prompt\n",
    "2. **Agent Execution**: Each agent receives:\n",
    "   - All domain expert prompts and analyses\n",
    "   - All previous agent prompts in the workflow\n",
    "   - Integration report from domain synthesis\n",
    "   - User's original query\n",
    "3. **Sequential Building**: Agent N+1 gets context from Agents 1 through N\n",
    "\n",
    "### ðŸ”„ **Modification Cascade**\n",
    "\n",
    "When you modify any agent's prompt:\n",
    "- That agent and **all subsequent agents** are automatically re-executed\n",
    "- The modified context propagates through the entire remaining workflow\n",
    "- Previous agents remain unchanged\n",
    "\n",
    "### ðŸ’¾ **Complete Traceability**\n",
    "\n",
    "- All prompts saved to individual text files\n",
    "- System state saved as JSON for full reproducibility\n",
    "- Conversation history maintained\n",
    "- Workflow progress tracking\n",
    "\n",
    "### ðŸŽ¯ **Key Benefits Achieved**\n",
    "\n",
    "âœ… **Prompt Chaining**: Each agent builds on all previous work  \n",
    "âœ… **Full Prompt Saving**: Every prompt (domain + agent) preserved  \n",
    "âœ… **Modification Cascade**: Changes automatically propagate  \n",
    "âœ… **Flexible Ordering**: Custom agent execution sequences  \n",
    "âœ… **Complete Audit Trail**: All decisions and prompts tracked  \n",
    "âœ… **State Management**: Full system state preservation  \n",
    "\n",
    "The system now works exactly as requested: **text-only input chaining** where each agent receives the **combined prompts** of all previous agents, enabling cumulative knowledge building without requiring agents to process the actual outputs of other agents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
